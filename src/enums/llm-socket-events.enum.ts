export enum LlmSocketEvents { 
      LLM_GENERATE_RESPONSE = "llm-generate-response",
      LLM_GENERATE_RESPONSE_BY_CHUNKS = "llm-generate-response-by-chunks",
      GET_ALL_OLLAMA_MODELS = "get-all-ollama-models",
      CANCEL_LLM_STREAM = "cancel-llm-stream",
}